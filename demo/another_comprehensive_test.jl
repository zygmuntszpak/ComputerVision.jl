using ComputerVision
using Test
using StaticArrays
using GeometryTypes
using LinearAlgebra
using PGFPlotsX
using Makie
using Colors

# Generate points on two planar surfaces
rois = [HyperRectangle(Vec(0.0, 0.0), Vec(150.0, 150.0)),
        HyperRectangle(Vec(0.0, 0.0), Vec(150.0, 150.0))]
pts = [24, 24]
planar_scene = PlanarSyntheticScene(total_planes = 2, regions_of_interest = rois, points_per_region = pts)
synthetic_scene_context = SyntheticSceneContext(planar_scene)

world, cameras = synthetic_scene_context()
cameraâ‚, cameraâ‚‚ = cameras


aquire = AquireImageContext()

# Project 3D points onto the cameras.
â„³ = aquire(world, cameraâ‚)
â„³â€² = aquire(world, cameraâ‚‚)

cameraâ‚  = deepcopy(cameraâ‚)
cameraáµ¦  = deepcopy(cameraâ‚‚)
worldâ‚‚ = deepcopy(world)

default_world_system = CartesianSystem(Point(0.0, 0.0, 0.0), Vec(1.0, 0.0, 0.0), Vec(0.0, 1.0, 0.0), Vec(0.0, 0.0, 1.0))
alternative_world_system = get_coordinate_system(get_extrinsics(get_model(cameraâ‚)))

transformation_context! = WorldCoordinateTransformationContext(CoordinateTransformation(source = default_world_system, target = alternative_world_system))
transformation_context!(cameraâ‚)
transformation_context!(cameraáµ¦)
transformation_context!(worldâ‚‚)

# Project transformed 3D points onto the cameras.
â„³â‚ = aquire(worldâ‚‚, cameraâ‚)
â„³áµ¦â€² = aquire(worldâ‚‚, cameraáµ¦)


# Verify that the coordinates of the image points are the same irrespective
# of the choice of the world coordinate system.
for couple in zip(â„³, â„³â‚)
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-10)
end
for couple in zip(â„³â€², â„³áµ¦â€²)
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-10)
end

# Verify that the original 3D points lie on their corresponding planes.
points3D = get_points(world)
planes3D = get_planes(world)
for (i, plane3D) in enumerate(planes3D)
    subset = points3D[get_interval(world.groups[i])]
    for pt in subset
        @test on_plane(pt, plane3D; tol = 1e-10)
    end
end

# Verify that the transformed 3D points lie on their corresponding transformed planes.
points3Dáµ¦ = get_points(worldâ‚‚)
planes3Dáµ¦ = get_planes(worldâ‚‚)
for (i, plane3Dáµ¦) in enumerate(planes3Dáµ¦)
    subset = points3Dáµ¦[get_interval(world.groups[i])]
    for pt in subset
        @test on_plane(pt, plane3Dáµ¦; tol = 1e-10)
    end
end

# Verify that the fundamental matrices are the same irrespective of how we choose
# the world coordinate system.
ğ…â‚ = matrix(FundamentalMatrix(cameraâ‚, cameraâ‚‚))
ğ…â‚ = ğ…â‚ / norm(ğ…â‚)
ğ…â‚‚ = matrix(FundamentalMatrix(cameraâ‚, cameraáµ¦))
ğ…â‚‚ = ğ…â‚‚ / norm(ğ…â‚‚)
@test norm(ğ…â‚ - ğ…â‚‚) < 1e-15


# Verify that the homography matrices are the same irrespective of how we choose
# the world coordinate system.
â„‹ = matrices(HomographyMatrices(cameraâ‚, cameraâ‚‚, get_planes(world)))
ğ‡â‚ = â„‹[1] / norm(â„‹[1])
ğ‡â‚ = ğ‡â‚ / sign(ğ‡â‚[end])
ğ‡â‚‚ = â„‹[2] / norm(â„‹[2])
ğ‡â‚‚ = ğ‡â‚‚ / sign(ğ‡â‚‚[end])

â„‹â‚‚ = matrices(HomographyMatrices(cameraâ‚, cameraáµ¦, get_planes(worldâ‚‚)))
ğ‡â‚ = â„‹â‚‚[1] / norm(â„‹â‚‚[1])
ğ‡â‚ = ğ‡â‚  / sign(ğ‡â‚[end])
ğ‡áµ¦ = â„‹â‚‚[2] / norm(â„‹â‚‚[2])
ğ‡áµ¦ = ğ‡áµ¦  / sign(ğ‡áµ¦[end])

@test norm(ğ‡â‚ .- ğ‡â‚) < 1e-15
@test norm(ğ‡â‚‚ .- ğ‡áµ¦) < 1e-15

# Verify that the homographies are compatible with the projected points
for (i, group) in enumerate(world.groups)
    allotment = get_interval(group)
    for corresponding_pair in zip(â„³[allotment], â„³â€²[allotment])
        ğ‡áµ¢ = â„‹[i]
        ğ¦ = corresponding_pair[1]
        ğ¦â€²  = homâ»Â¹(ğ‡áµ¢ * hom(ğ¦))
        @test isapprox(norm(ğ¦â€² - corresponding_pair[2]), 0.0; atol = 1e-10)
    end
end


# Verify that the points are triangulated correctly for both choices of
# world coordinate systems.
ğ’â‚ = Correspondences((â„³,â„³â€²))
triangulate_points =  TriangulateContext(DirectLinearTriangulation())
estimated_pointsâ‚ = triangulate_points(cameraâ‚, cameraâ‚‚, ğ’â‚)
# Verify that the triangulated points are close to the true points.
for couple in zip(estimated_pointsâ‚, get_points(world))
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-7)
end

ğ’â‚‚ = Correspondences((â„³â‚,â„³áµ¦â€²))
triangulate_points =  TriangulateContext(DirectLinearTriangulation())
estimated_pointsâ‚‚ = triangulate_points(cameraâ‚, cameraáµ¦, ğ’â‚‚)
# Verify that the triangulated points are close to the true points.
for couple in zip(estimated_pointsâ‚‚, get_points(worldâ‚‚))
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-7)
end

analogue_imageâ‚ = get_image_type(cameraâ‚)
analogue_imageâ‚‚ = get_image_type(cameraâ‚‚)

extract_pose = PoseFromSingleHomographyContext(intrinsics = get_intrinsics(get_model(cameraâ‚)), image_type = analogue_imageâ‚, algorithm = MalisVargasDecomposition())

for (i, group) in enumerate(world.groups)
    # Obtain the ground truth
    relative_pose = RelativePose(cameraâ‚, cameraáµ¦)
    R = ComputerVision.rotation(relative_pose)
    t = ComputerVision.translation(relative_pose)
    planes = get_planes(worldâ‚‚)
    plane = planes[i]
    ğ§ = get_normal(plane)
    d = get_distance(plane)
    # Convention used by Malis and Vargas in their homography decomposition paper.
    ğ‘ = R'
    ğ­ = (-R'*t) / d

    # Extract the corresponding points associated with the current plane
    allotment = get_interval(world.groups[i])
    ğ’ = Correspondences((â„³â‚[allotment],â„³áµ¦â€²[allotment]))

    # Construct two potential solutions
    potential_poses = extract_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, plane), ğ’)
    # One of the poses should correspond with the truth (taking into account numerical errors)
    Aâ‚, bâ‚, vâ‚ =  potential_poses[1]
    Aâ‚‚, bâ‚‚, vâ‚‚ =  potential_poses[2]
    testâ‚ = norm(Aâ‚ - ğ‘) < 1e-7 && norm(bâ‚ - ğ­) < 1e-7 && norm(vâ‚ - ğ§) < 1e-7
    testâ‚‚ = norm(Aâ‚‚ - ğ‘) < 1e-7 && norm(bâ‚‚ - ğ­) < 1e-7 && norm(vâ‚‚ - ğ§) < 1e-7
    @test testâ‚ || testâ‚‚
end



# relative_pose = RelativePose(cameraâ‚, cameraáµ¦)
# R = ComputerVision.rotation(relative_pose)
# t = ComputerVision.translation(relative_pose)
# planes = get_planes(worldâ‚‚)
# plane = planes[1]
# ğ§ = get_normal(plane)
# d = get_distance(plane)
# # Convention used by Malis and Vargas in their homography decomposition paper.
# ğ‘ = R'
# ğ­ = (-R'*t) / d
#
#
# allotmentâ‚ = get_interval(groups[1])
# ğ’â‚ = Correspondences((â„³â‚[allotmentâ‚],â„³áµ¦â€²[allotmentâ‚]))
# valid_poses = extract_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, first(get_planes(worldâ‚‚))), ğ’â‚)
# A, b, v = valid_poses[1]
# Aâ‚š = A'
# bâ‚š = -A' * b * d


#
#
# # One of the valid poses should correspond with the truth (taking into account numerical errors)
# Aâ‚, bâ‚, vâ‚ =  valid_poses[1]
# Aâ‚‚, bâ‚‚, vâ‚‚ =  valid_poses[2]
# testâ‚ = norm(Aâ‚ - ğ‘) < 1e-7 && norm(bâ‚ - ğ­) < 1e-7 && norm(vâ‚ - ğ§) < 1e-7
# testâ‚‚ = norm(Aâ‚‚ - ğ‘) < 1e-7 && norm(bâ‚‚ - ğ­) < 1e-7 && norm(vâ‚‚ - ğ§) < 1e-7
# @test testâ‚ || testâ‚‚
#
# # Second plane?
# relative_pose = RelativePose(cameraâ‚, cameraáµ¦)
# R = ComputerVision.rotation(relative_pose)
# t = ComputerVision.translation(relative_pose)
# planes = get_planes(worldâ‚‚)
# plane = planes[2]
# ğ§ = get_normal(plane)
# d = get_distance(plane)
# # Convention used by Malis and Vargas in their homography decomposition paper.
# ğ‘ = R'
# ğ­ = (-R'*t) / d
#
# ğ§
#
# extract_pose = PoseFromSingleHomographyContext(intrinsics = get_intrinsics(get_model(cameraâ‚)), image_type = analogue_imageâ‚, algorithm = MalisVargasDecomposition(), use_outward_normal_convention = true)
# poses = extract_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, last(get_planes(worldâ‚‚))), ğ’â‚‚)
# poses
#
# allotmentâ‚‚ = get_interval(groups[2])
# ğ’â‚‚ = Correspondences((â„³â‚[allotmentâ‚‚],â„³áµ¦â€²[allotmentâ‚‚]))
# ğ’â‚‚ = Correspondences((â„³â‚,â„³áµ¦â€²))
# #valid_poses = determine_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, last(get_planes(worldâ‚‚))), ğ’â‚‚)
#
#
# # One of the valid poses should correspond with the truth (taking into account numerical errors)
# Aâ‚, bâ‚, vâ‚ =  valid_poses[1]
# Aâ‚‚, bâ‚‚, vâ‚‚ =  valid_poses[2]
# testâ‚ = norm(Aâ‚ - ğ‘) < 1e-7 && norm(bâ‚ - ğ­) < 1e-7 && norm(vâ‚ - ğ§) < 1e-7
# testâ‚‚ = norm(Aâ‚‚ - ğ‘) < 1e-7 && norm(bâ‚‚ - ğ­) < 1e-7 && norm(vâ‚‚ - ğ§) < 1e-7
# @test testâ‚ || testâ‚‚
#
#
# poses
#
# ğŠ = to_matrix(get_intrinsics(get_model(cameraâ‚)), OpticalSystem())
# ğ† = ğŠ*(ğ‘ + ğ­*ğ§')*inv(ğŠ)
# ğ† = ğ† / norm(ğ†)
# ğ† = ğ† / sign(ğ†[end])
# ğ‡â‚ = ğ‡â‚ / sign(ğ‡â‚[end])
# ğ‡â‚ = ğ‡â‚  / sign(ğ‡â‚[end])
# @test norm(ğ‡â‚ .- ğ†) < 1e-15
# @test norm(ğ‡â‚ .- ğ†) < 1e-15
#
#
# ğ§
# ğ­
#
#
#
#
#
#
# #poses = determine_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, first(get_planes(worldâ‚‚))))
#
#
# for pose in poses
#     A, b, v =  pose
#     @show 1 + v'*A'*b
# end
#
# valid_poses
#
#
#
# poses
# #
# # posesâ‚‚ = determine_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, last(get_planes(worldâ‚‚))))
# #
# # ascertain_pose(cameraáµ¦, default_world_system)
# #
# #
# #
# # analogue_imageâ‚
# #
# # valid_poses = determine_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, first(get_planes(worldâ‚‚))), Correspondences((â„³â‚,â„³áµ¦â€²)))
# #
# # valid_poses
# #
# # poses
#
#
#
#
#
# posesâ‚‚
