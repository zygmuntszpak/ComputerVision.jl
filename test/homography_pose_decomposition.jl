using ComputerVision
using Test
using StaticArrays
using GeometryTypes
using LinearAlgebra
using PGFPlotsX
using Makie
using Colors

# Generate points on two planar surfaces
xâ‚ = 0.0
xâ‚â€² = 0.0
yâ‚ = -1000.0
yâ‚â€² = 2000.0
zâ‚ = -1000.0
zâ‚â€² = 1000.0
pointsâ‚ = [Point3(rand(xâ‚:xâ‚â€²), rand(yâ‚:yâ‚â€²), rand(zâ‚:zâ‚â€²)) for n = 1:250]
planeâ‚ = [Plane(Vec3(1.0, 0.0, 0.0), 0)]
pâ‚ = [xâ‚, yâ‚, zâ‚]
qâ‚ = [xâ‚, yâ‚â€², zâ‚]
râ‚ = [xâ‚, yâ‚â€², zâ‚â€²]
sâ‚ = [xâ‚, yâ‚, zâ‚â€²]
segmentâ‚ = [pâ‚ => qâ‚ , qâ‚ => râ‚ , râ‚ => sâ‚ , sâ‚ => pâ‚]
plane_segmentâ‚ = PlaneSegment(first(planeâ‚), segmentâ‚)

xâ‚‚ = 0.0
xâ‚‚â€² = 3000.0
yâ‚‚ = 2000.0
yâ‚‚â€² = 2000.0
zâ‚‚ = -1000.0
zâ‚‚â€² = 1000.0
pointsâ‚‚ = [Point3(rand(xâ‚‚:xâ‚‚â€²), rand(yâ‚‚:yâ‚‚â€²), rand(zâ‚‚:zâ‚‚â€²)) for n = 1:250]
planeâ‚‚ = [Plane(Vec3(0.0, 1.0, 0.0), 2000)]
pâ‚‚ = [xâ‚‚, yâ‚‚, zâ‚‚]
qâ‚‚ = [xâ‚‚, yâ‚‚, zâ‚‚â€²]
râ‚‚ = [xâ‚‚â€², yâ‚‚, zâ‚‚â€²]
sâ‚‚ = [xâ‚‚â€², yâ‚‚, zâ‚‚]
segmentâ‚‚ = [pâ‚‚ => qâ‚‚ , qâ‚‚ => râ‚‚ , râ‚‚ => sâ‚‚ , sâ‚‚ => pâ‚‚]
plane_segmentâ‚‚ = PlaneSegment(first(planeâ‚‚), segmentâ‚‚)

planes = vcat(planeâ‚, planeâ‚‚)
#planes = vcat(plane_segmentâ‚, plane_segmentâ‚‚)
points = vcat(pointsâ‚, pointsâ‚‚)

groups = [IntervalAllotment(1:250), IntervalAllotment(251:500)]

world = PrimitiveWorld(points = points, planes = planes, groups = groups)

pinholeâ‚ = Pinhole(intrinsics = IntrinsicParameters(width = 640, height = 480, focal_length = 100))
analogue_imageâ‚ = AnalogueImage(coordinate_system = OpticalSystem())
cameraâ‚ = ComputerVision.Camera(image_type = analogue_imageâ‚, model = pinholeâ‚)
ğ‘â‚ = SMatrix{3,3,Float64,9}(rotxyz(90*(pi/180), -110*(pi/180), 0*(pi/180)))
ğ­â‚ = [3000.0,0.0, 0.0]
relocate!(cameraâ‚, ğ‘â‚, ğ­â‚)

pinholeâ‚‚ = Pinhole(intrinsics = IntrinsicParameters(width = 640, height = 480, focal_length = 100))
analogue_imageâ‚‚ = AnalogueImage(coordinate_system = OpticalSystem())
cameraâ‚‚ = ComputerVision.Camera(image_type = analogue_imageâ‚‚, model = pinholeâ‚‚)
ğ‘â‚‚ = SMatrix{3,3,Float64,9}(rotxyz(90*(pi/180), -110*(pi/180), 0*(pi/180)))
ğ­â‚‚ = [4000.0,0.0, 0.0]
relocate!(cameraâ‚‚, ğ‘â‚‚, ğ­â‚‚)


aquire = AquireImageContext()

# Project 3D points onto the cameras.
â„³ = aquire(world, cameraâ‚)
â„³â€² = aquire(world, cameraâ‚‚)

cameraâ‚  = deepcopy(cameraâ‚)
cameraáµ¦  = deepcopy(cameraâ‚‚)
worldâ‚‚ = deepcopy(world)

default_world_system = CartesianSystem(Point(0.0, 0.0, 0.0), Vec(1.0, 0.0, 0.0), Vec(0.0, 1.0, 0.0), Vec(0.0, 0.0, 1.0))
alternative_world_system = get_coordinate_system(get_extrinsics(get_model(cameraâ‚)))

transformation_context! = WorldCoordinateTransformationContext(CoordinateTransformation(source = default_world_system, target = alternative_world_system))
transformation_context!(cameraâ‚)
transformation_context!(cameraáµ¦)
transformation_context!(worldâ‚‚)

# Project transformed 3D points onto the cameras.
â„³â‚ = aquire(worldâ‚‚, cameraâ‚)
â„³áµ¦â€² = aquire(worldâ‚‚, cameraáµ¦)


# Verify that the original 3D points lie on their corresponding planes.
points3D = get_points(world)
planes3D = get_planes(world)
for (i, plane3D) in enumerate(planes3D)
    subset = points3D[get_interval(groups[i])]
    for pt in subset
        @test on_plane(pt, plane3D; tol = 1e-10)
    end
end

# Verify that the transformed 3D points lie on their corresponding transformed planes.
points3Dáµ¦ = get_points(worldâ‚‚)
planes3Dáµ¦ = get_planes(worldâ‚‚)
for (i, plane3Dáµ¦) in enumerate(planes3Dáµ¦)
    subset = points3Dáµ¦[get_interval(groups[i])]
    for pt in subset
        @test on_plane(pt, plane3Dáµ¦; tol = 1e-10)
    end
end


â„‹ = matrices(HomographyMatrices(cameraâ‚, cameraâ‚‚, get_planes(world)))

# Verify that the homographies are compatible with the projected points
for (i, group) in enumerate(groups)
    allotment = get_interval(group)
    for corresponding_pair in zip(â„³[allotment], â„³â€²[allotment])
        ğ‡áµ¢ = â„‹[i]
        ğ¦ = corresponding_pair[1]
        ğ¦â€²  = homâ»Â¹(ğ‡áµ¢ * hom(ğ¦))
        @test isapprox(norm(ğ¦â€² - corresponding_pair[2]), 0.0; atol = 1e-10)
    end
end


extract_pose = PoseFromSingleHomographyContext(intrinsics = get_intrinsics(get_model(cameraâ‚)), image_type = analogue_imageâ‚, algorithm = MalisVargasDecomposition())
for (i, group) in enumerate(groups)
    # Obtain the ground truth
    relative_pose = RelativePose(cameraâ‚, cameraáµ¦)
    R = ComputerVision.rotation(relative_pose)
    t = ComputerVision.translation(relative_pose)
    planes = get_planes(worldâ‚‚)
    plane = planes[i]
    ğ§ = get_normal(plane)
    d = get_distance(plane)
    # Note the convention used by Malis and Vargas in their homography decomposition paper.
    ğ‘ = R'
    ğ­ = (-R'*t) / d

    # Extract the corresponding points associated with the current plane
    allotment = get_interval(groups[i])
    ğ’ = Correspondences((â„³â‚[allotment],â„³áµ¦â€²[allotment]))

    # Construct two potential solutions
    potential_poses = extract_pose(HomographyMatrix(cameraâ‚, cameraáµ¦, plane), ğ’)
    # One of the poses should correspond with the truth (taking into account numerical errors)
    Aâ‚, bâ‚, vâ‚ =  potential_poses[1]
    Aâ‚‚, bâ‚‚, vâ‚‚ =  potential_poses[2]
    testâ‚ = norm(Aâ‚ - ğ‘) < 1e-7 && norm(bâ‚ - ğ­) < 1e-7 && norm(vâ‚ - ğ§) < 1e-7
    testâ‚‚ = norm(Aâ‚‚ - ğ‘) < 1e-7 && norm(bâ‚‚ - ğ­) < 1e-7 && norm(vâ‚‚ - ğ§) < 1e-7
    @test testâ‚ || testâ‚‚
end
